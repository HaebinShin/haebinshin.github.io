---
layout: post
title: Grad-CAM
category: c1
---

Grad-CAM은 모델이 왜 이러한 결과로 prediction 했는지 이유를 "gradient" 기반으로 visualization 하는 논문이다. 본 포스팅에서는 Grad-CAM을 알아보기에 앞서, Weakly-supervised learning와 CAM의 관점에서 Grad-CAM의 의미를 분석해보고자 한다.

---

## Weakly-Supervised Learning

<p class="cite">
M. Oquab, L. Bottou, I. Laptev, and J. Sivic. Learning and transferring mid-level image representations using convolutional neural networks. In CVPR, 2014.
</p>

> "Object Classification 학습만으로도 Object Localization이 가능하다"

Object Recognition과 같은 문제를 해결할 때, 많은 양의 Anootated Image 데이터를 필요로 한다. 예를 들어 "Object가 어느 위치에 있는가?" 와 같은 Segmentation Annotaion을 만드는 일은 매우 많은 손이 필요하다. 본 논문은 비교적 annotation이 쉬운 Object Classification 문제를 학습하고, CNN의 high representation을 활용하여 Object Localization 문제 해결에 적용한다. 이러한 방법을 Weakly Supervised Learning이라고 부른다.

### Contrib 1. Weakly Supervised Learning
- 사진 내 object의 존재 유무는 annotate 되어있지만, 어느 위치에 있는지 position annotation은 하지 않고 학습
- 사진에 대한 여러 object들이 labeling 되기 때문에 이는 multi label 문제이다.
    - 즉, 각 class별로 sigmoid 하여 문제 해결.
- CNN 구조 마지막 부분에 adaptation layer를 제안

    ![/public/img/adaptation_layer.png](/public/img/adaptation_layer.png)

    - k개 만큼의 multi label 개수로 feature map channel을 만들고, global max-pooling을 통해 각 feature map의 채널을 각 label 당 하나의 스칼라로 만든다. (1 x 1 x K)
    - 그 스칼라들을 각각 sigmoid를 통해 각 label 별 존재 유무를 predict 한다.
    - multi-label loss는 각 class 별 sigmoid cross entropy의 sum
    - multi label로 학습하기 때문에 ,
    positive label에 대한 feature map channel은 강해지고,
    negative label에 대한 feature map channel은 약해지는 방향으로 학습

### Contrib 2. Weakly supervised learning의 Classification, Localization 평가
- Classification은 각 class별 precision에 대한 전체적 mean average precision 사용
- Classification 테스크에서 위에서 사용한 Global max-pooling말고, mask pooling을 통해 localization label에 해당하는 부분만 마스크를 씌워 학습시키면 classification 성능이 좋아질까?
    - 별 차이 없음. Localization 데이터를 학습해도 Object-level Task로부터 전이된 Weakly Supervised Learning에는 큰 효과를 주지 못한다. 즉, (localization label이 없는 weakly 데이터로) Weakly Supervised Learning이 가능함을 입증.
- Weakly Supervised Learning으로 Classification 학습에 사용된 feature map에서 가장 큰 값에 주목함으로써 localization 여부를 확인해볼 수 있다.
- Location Prediction Metrics
    - Label이 k일 때, 그에 대응되는 k개의 feature map이 있는데, 그 map을 input 이미지 크기로 rescale한다. (본 논문에서는 단순 interpolation으로 복원)
    - rescale된 map에서 maximal value가 location label box 범위와 18 pixel 이내에
    있다면 correct, 아니라면 false positive라고 평가. 
    (네트워크의 pooling ratio (rescale 오차범위)를 고려해 18 pixel tolerance 설정)
- Localization은 fully-supervised learning (R-CNN)과 비교해봄
    - 성능 거의 비슷, 즉 weakly 데이터를 써도 좋다는걸 입증.

---

## CAM

<p class="cite">
B. Zhou, A. Khosla, L. A., A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization. In CVPR, 2016.
</p>

Reference: [Blog](http://tmmse.xyz/2016/04/10/object-localization-with-weakly-supervised-learning/)

CAM은 Weakly-supervised Object Localization 문제에 대해 class별로 왜 이런 결과가 predict 되었는지 이유를 visualization 하고자 한다. 본 논문에서 주장하는 주요 내용은 아래와 같다.

### Global Average Pooling(GAP)이 Global Max Pooling(GMP)보다 좋다.
- 위에서 언급한 이전 논문에서는 GMP를 이용한 Adaptation Layer를 거쳐 multi-label 문제를 학습하였다.
- 본 논문에서는 GMP와 GAP의 차이를 소개하며, GAP로 대체하였다.
    - GAP loss는 전반적인 object identification에 강한 반면, 
    GMP loss는 object 내 가장 discriminative한 부분에 집중한다.
    - GAP는 낮은 activation 값이 섞여있을 때 전체 output도 영향을 받지만,
    GMP는 낮은 activation이 섞여 있더라도 most discriminative part만 선택되기 때문에 아무 피드백도 받지 못한다.

### CAM Architecture

![/public/img/cam_architecture.png](/public/img/cam_architecture.png)

- 위에서 언급한 이전 논문에서는 k개의 feature map을 GMP 연산으로 k개의 scala로 만든 후 끝
- 본 논문은 k개의 feature map을 gap 연산으로 k개의 scala로 만든 후, FC layer 하나를 거쳐 마지막 Output layer 출력
- k개의 scala는 GAP로 만들었기 때문에 각 feature map의 모든 grid value를 반영하게 되고, 
이는 곧 마지막 FC layer가 k개의 feature map에 어떤 가중치 곱하여 i번째 class를 predict 한다는 의미이다.

### CAM의 원리
- $f_k(x,y)$를 k번째 feature map의 x,y grid value라고 했을 때, 각 class 별로 predict score는 아래 식에 의해 완성된다. (normalized term은 생략)

$$ GAP = \underset{x,y}{\Sigma}f_k(x,y) $$

$$ S_c = \underset{k}{\Sigma}w_k^c\underset{x,y}{\Sigma}f_k(x,y) = \underset{x,y}{\Sigma}\underset{k}{\Sigma}w_k^cf_k(x,y) $$

$$ M_c(x,y) = \underset{k}{\Sigma}w_k^cf_k(x,y) $$

$$ S_c = \underset{x,y}{\Sigma}M_c(x,y) $$

- 즉, GAP 연산 후 FC Layer에 의해 $c$(class)에 대한 activation map(CAM) $M_c$를 도출한다.
- $M_c$는 feature map의 크기와 같고, 이를 입력 이미지 크기로 upsampling해서 visualize할 수 있다.

### Localization
- object localization은 CAM에 20% threshold를 주어 bounding box를 만든다.

---

## Grad-CAM
<p class="cite">
R.R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh and D. Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization. In ICCV, 2017.
</p>

To be continued..